# ROB2 Evaluator Environment Configuration
# Copy this file to .env and modify the values as needed

# ==============================================
# AI Model Configuration
# ==============================================

# Model provider selection
# Supported: ANTHROPIC, OPENAI, DEEPSEEK, GROQ, GOOGLE, OLLAMA
MODEL_PROVIDER=OLLAMA

# Model name (depends on provider)
# For OLLAMA: gemma3:27b, llama3:8b, etc.
# For ANTHROPIC: claude-3-sonnet-20240229, claude-3-haiku-20240307, etc.
# For OPENAI: gpt-4, gpt-3.5-turbo, etc.
# For DEEPSEEK: deepseek-chat, deepseek-coder, etc.
MODEL_NAME=gemma3:27b

# ==============================================
# API Keys (only needed for cloud providers)
# ==============================================

# Anthropic Claude API Key
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key
# OPENAI_API_KEY=your_openai_api_key_here

# DeepSeek API Key
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Google Gemini API Key
# GOOGLE_API_KEY=your_google_api_key_here

# Groq API Key
# GROQ_API_KEY=your_groq_api_key_here

# ==============================================
# Local Model Configuration (Ollama)
# ==============================================

# Ollama server base URL
OLLAMA_BASE_URL=http://localhost:11434

# ==============================================
# Quality Review Configuration
# ==============================================

# Enable/disable quality review system
# Values: true, false, 1, 0, yes, no, on, off
# Default: true (enabled)
ENABLE_REVIEW=true

# ==============================================
# Processing Configuration
# ==============================================

# Cache directory for processed results
# CACHE_DIR=.cache

# Number of concurrent threads for domain evaluation
# DOMAIN_EVALUATION_THREADS=5

# Enable verbose logging
# LOG_LEVEL=INFO

# ==============================================
# Development Configuration
# ==============================================

# Enable debug mode
# DEBUG=false

# Test mode (for development)
# TEST_MODE=false

# ==============================================
# Usage Examples
# ==============================================

# Example 1: Use Claude with review enabled
# MODEL_PROVIDER=ANTHROPIC
# MODEL_NAME=claude-3-sonnet-20240229
# ANTHROPIC_API_KEY=your_key_here
# ENABLE_REVIEW=true

# Example 2: Use local Ollama model without review
# MODEL_PROVIDER=OLLAMA
# MODEL_NAME=llama3:8b
# OLLAMA_BASE_URL=http://localhost:11434
# ENABLE_REVIEW=false

# Example 3: Use OpenAI GPT-4 with custom cache
# MODEL_PROVIDER=OPENAI
# MODEL_NAME=gpt-4
# OPENAI_API_KEY=your_key_here
# ENABLE_REVIEW=true
# CACHE_DIR=/path/to/custom/cache